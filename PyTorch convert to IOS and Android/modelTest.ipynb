{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение и тест модели MLPModel\n",
    "1. Подготовка данных ф-ия MLPDataset из dataset.py\n",
    "2. Определение функции потерь и оптимизатора (MSE - среднеквадратичная ошибка,SGD - стохастический градиентный спуск)\n",
    "3. Обучение модели\n",
    "4. Обучение и тестирование на Кросс-Валидации, тк у нас очень маленькая выборка\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from linRegres import MLPModel\n",
    "from dataset import MLPDataset,MLPTesDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт модели\n",
    "model = MLPModel()\n",
    "#MSE\n",
    "criterion = nn.MSELoss()  \n",
    "# Стохастический градиентный спуск\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  #Епсилон = 0.1 с учетом нашего датасета [-1;1] это приемлемое значение\n",
    "\n",
    "# Получение датасета и DataLoader\n",
    "equalDataset = MLPDataset()\n",
    "dataset = equalDataset['dataset']\n",
    "train_loader = equalDataset['train_loader']  # Этот DataLoader мы не используем напрямую\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "k_folds = 5\n",
    "epochs = 200\n",
    "# Функция для обучения модели\n",
    "def train_model(model_q, criterion_q, optimizer_q, train_loader_q, epochs_q):\n",
    "    model_q.train()  # Перевод модели в режим обучения\n",
    "    for epoch in range(epochs_q):\n",
    "        for inputs, labels in train_loader_q:\n",
    "            optimizer_q.zero_grad()\n",
    "            outputs = model_q(inputs)\n",
    "            loss = criterion_q(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_q.step()\n",
    "            \n",
    "# Функция проверки модели\n",
    "def test_model(model, criterion, test_loader):\n",
    "    model.eval()  # Переключаем модель в режим оценки (валидации)\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Отключаем вычисление градиентов\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)  # Умножаем потерю на размер пакета для учета разного размера пакетов\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples  # Считаем среднюю потерю\n",
    "    print(f'Средняя потеря на тестовом наборе: {avg_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n",
      "Test Loss for fold 0: 0.006255189422518015\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Test Loss for fold 1: 0.003521340200677514\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Test Loss for fold 2: 0.006525344680994749\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Test Loss for fold 3: 0.003364887088537216\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Test Loss for fold 4: 0.0038740055169910192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Настройка KFold\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Запуск k-фолд кросс-валидации\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold+1}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    # Сэмплеры для обучающего и тестового набора\n",
    "    train_subsampler = SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # DataLoader'ы для текущего разбиения\n",
    "    train_loader = DataLoader(dataset, batch_size=10, sampler=train_subsampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=10, sampler=test_subsampler)\n",
    "    \n",
    "    # Обучение модели\n",
    "    train_model(model, criterion, optimizer, train_loader, epochs)\n",
    "    \n",
    "    # Тестирование модели\n",
    "    model.eval()  # Перевод модели в режим оценки\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    print(f'Test Loss for fold {fold}: {total_loss / len(test_loader)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря на тестовом наборе: 12.625688909948803\n"
     ]
    }
   ],
   "source": [
    "# Создание тестового набора данных\n",
    "test_data = MLPTesDataset()\n",
    "test_loader = test_data['test_loader']\n",
    "\n",
    "# Проверка модели\n",
    "test_model(model, criterion, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
