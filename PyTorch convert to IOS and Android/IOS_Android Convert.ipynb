{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаги для подготовки модели к развертыванию:\n",
    "Оптимизация модели:\n",
    "\n",
    "Уменьшение размера модели: Это может включать в себя уменьшение количества слоев или нейронов в каждом слое. Для более сложных моделей можно применять техники квантования или прунинга.\n",
    "Квантование: Позволяет снизить точность весов модели, например, с 32-битных чисел с плавающей точкой до 8-битных целых чисел, с минимальной потерей качества.\n",
    "Проверка производительности модели: Убедитесь, что оптимизация не привела к значительной потере точности.\n",
    "Использование подходящих инструментов:\n",
    "\n",
    "Для iOS (устройства Apple) часто используется Core ML. Вы можете конвертировать обученную модель в формат Core ML с помощью инструмента, такого как coremltools.\n",
    "Для Android можно использовать TensorFlow Lite. TensorFlow предоставляет инструменты для конвертации моделей в формат .tflite, который эффективно работает на мобильных устройствах.\n",
    "Тестирование на устройствах:\n",
    "\n",
    "После конвертации и интеграции модели в приложение проведите тестирование на разных устройствах, чтобы убедиться в её работоспособности и производительности.\n",
    "Особое внимание уделите скорости инференса и потреблению памяти, так как эти факторы критически важны для мобильных устройств."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестирования производительности и ресурсоэффективности модели машинного обучения на мобильных устройствах, важно оценить несколько ключевых параметров. Эти параметры включают время выполнения (инференса), потребление памяти, использование процессора и, при необходимости, использование графического процессора (GPU). Вот несколько подходов и инструментов, которые можно использовать для тестирования:\n",
    "\n",
    "1. Время выполнения (скорость инференса)\n",
    "Использование профайлеров:\n",
    "Android Studio Profiler: Позволяет отслеживать использование CPU, памяти и сетевую активность вашего приложения в реальном времени. Вы можете использовать его для измерения времени, необходимого для выполнения инференса вашей модели.\n",
    "Xcode Instruments: Инструменты для профилирования приложений на iOS, которые предоставляют детальную информацию о производительности приложения, включая время выполнения задач.\n",
    "2. Потребление памяти\n",
    "Memory Profiler в Android Studio и Instruments в Xcode: Эти инструменты позволяют отслеживать использование памяти вашим приложением. Они могут помочь выявить утечки памяти и другие проблемы, которые могут возникнуть при выполнении инференса модели.\n",
    "3. Энергопотребление\n",
    "Battery Profiler в Android Studio: Предоставляет информацию о том, как ваше приложение влияет на заряд батареи устройства.\n",
    "Energy Log в Instruments для iOS: Помогает определить, как использование вашего приложения влияет на энергопотребление устройства.\n",
    "4. Тестирование на реальных устройствах\n",
    "Важно провести тестирование на реальных устройствах с различными характеристиками (в том числе на устройствах с низкими характеристиками), чтобы убедиться в том, что приложение работает корректно и эффективно использует ресурсы.\n",
    "Практические шаги для тестирования:\n",
    "Интеграция модели в приложение: После конвертации модели в соответствующий формат (например, .tflite или .mlmodel) интегрируйте её в ваше мобильное приложение.\n",
    "\n",
    "Разработка тестовых сценариев: Создайте сценарии использования, которые имитируют реальные условия работы приложения. Это может включать инференс на живом видео, анализ изображений, обработку текста и т.д.\n",
    "\n",
    "Запуск тестов и сбор данных: Используйте вышеупомянутые профайлеры и инструменты для сбора данных о производительности и ресурсоэффективности вашей модели в различных условиях.\n",
    "\n",
    "Анализ результатов и оптимизация: Анализируйте полученные данные, идентифицируйте узкие места и проблемы. В зависимости от результатов, вы можете потребоваться дополнительная оптимизация модели или изменение логики приложения.\n",
    "\n",
    "Тестирование на разных устройствах и в различных условиях поможет убедиться, что ваше приложение эффективно работает и оптимально использует ресурсы мобильного устройства, обеспечивая при этом необходимое качество инференса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конвертация модели PyTorch в формат, совместимый с iOS, обычно включает в себя несколько шагов, включая оптимизацию модели и её экспорт в формат Core ML, который поддерживается устройствами Apple. Вот основные этапы процесса:\n",
    "\n",
    "    Оптимизация модели PyTorch: Перед тем как конвертировать модель, важно убедиться, что она оптимизирована для эффективности на мобильных устройствах. Это может включать в себя уменьшение размера модели, прунинг (удаление неиспользуемых весов) и квантизацию.\n",
    "\n",
    "    Экспорт в ONNX: Модель PyTorch можно экспортировать в формат ONNX, который является промежуточным стандартом для представления моделей машинного обучения. Это делается с помощью функции torch.onnx.export.\n",
    "\n",
    "    Конвертация ONNX в Core ML: Для конвертации из ONNX в Core ML можно использовать инструмент onnx-coreml. Этот инструмент поддерживает прямую конвертацию и позволяет дополнительно адаптировать модель под нужды iOS.\n",
    "\n",
    "    Интеграция в iOS приложение: После конвертации модели в Core ML, следующим шагом будет её интеграция в iOS-приложение. Это включает добавление .mlmodel файла в проект Xcode и использование Core ML API для работы с моделью.\n",
    "\n",
    "    Тестирование на устройстве: Важно тестировать модель на реальном устройстве, чтобы убедиться, что она работает корректно и эффективно. Это включает проверку производительности и точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "#import onnx\n",
    "#from onnx_coreml import convert\n",
    "from torchsummary import summary\n",
    "import coremltools as ct\n",
    "\n",
    "\n",
    "from linRegres import MLPModel,LinearRegressionModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Linear: 1-1                            2\n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Linear: 1-1                            2\n",
       "=================================================================\n",
       "Total params: 2\n",
       "Trainable params: 2\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание экземпляра модели\n",
    "model = LinearRegressionModel(input_size=1, output_size=1)\n",
    "\n",
    "# Загрузка весов\n",
    "path_to_weights = 'model_params.pth'\n",
    "model_weights = torch.load(path_to_weights)\n",
    "\n",
    "# Применение загруженных весов к модели\n",
    "model.load_state_dict(model_weights)\n",
    "\n",
    "# Перевод модели в режим оценки (если модель используется для инференса)\n",
    "model.eval()\n",
    "\n",
    "# Вывод сводной информации о модели\n",
    "summary(model, input_size=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
